import copy

import torch
import torch.nn as nn
import tensorflow as tf
from art.attacks.inference.membership_inference import ShadowModels
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

import load_data

malware_images = tf.convert_to_tensor(load_data.load_malware_images())
benign_images = tf.convert_to_tensor(load_data.load_benign_images())

# Reshape the tensors to have 2 dimensions
malware_images_2d = tf.reshape(malware_images, (malware_images.shape[0], -1))
benign_images_2d = tf.reshape(benign_images, (benign_images.shape[0], -1))

# Convert tensors to numpy arrays for scaling
malware_images_2d_np = malware_images_2d.numpy()
benign_images_2d_np = benign_images_2d.numpy()

# Apply the StandardScaler
scaler = StandardScaler()
malware_images_scaled = scaler.fit_transform(malware_images_2d_np)
benign_images_scaled = scaler.fit_transform(benign_images_2d_np)

# Convert back to tensors
malware_images_scaled_2d = tf.convert_to_tensor(malware_images_scaled)
benign_images_scaled_2d = tf.convert_to_tensor(benign_images_scaled)

# Reshape the scaled tensors back to the original 3D shape
malware_images_scaled_3d = tf.reshape(malware_images_scaled_2d, malware_images.shape)
benign_images_scaled_3d = tf.reshape(benign_images_scaled_2d, benign_images.shape)

x = np.concatenate((malware_images_scaled_3d, benign_images_scaled_3d), axis=0)
y = np.concatenate((np.ones(len(malware_images_scaled_3d)), np.zeros(len(benign_images_scaled_3d))))

# Shuffle data
shuffle_idx = np.random.permutation(len(x))
x = x[shuffle_idx]
y = y[shuffle_idx]

# split data to 80 percent training and 20 percent testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
# (x_target, y_target), (x_shadow, y_shadow), _, _ = train_test_split(x,y, test_set=0.2)

# for my shadow model, I will reverse them, using test as training and training as test
x_train_shadow, x_test_shadow, y_train_shadow, y_test_shadow = x_test, x_train, y_test, y_train

# Convert TensorFlow model to PyTorch model
torch_model = nn.Sequential(
    nn.Conv2d(1, 32, kernel_size=(3, 3)),
    nn.ReLU(),
    nn.MaxPool2d((2, 2)),
    nn.Flatten(),
    nn.Linear(2592, 128),
    nn.ReLU(),
    nn.Linear(128, 1),
    nn.Sigmoid()
)

# Convert the model to the device (e.g., GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch_model.to(device)


# Define a wrapper class to provide the `clone_for_refitting` method
class TorchModelWrapper:
    def __init__(self, model):
        self.model = model
        self.input_shape = (1,) + tuple(model[0].weight.shape[1:])

    def predict(self, x):
        with torch.no_grad():
            self.model.eval()
            x_tensor = torch.from_numpy(x).to(device)
            return self.model(x_tensor).cpu().numpy()

    def clone_for_refitting(self):
        return TorchModelWrapper(copy.deepcopy(self.model))


# Wrap the PyTorch model with the wrapper class
torch_wrapper = TorchModelWrapper(torch_model)

# Create shadow models using the wrapped PyTorch model
shadow_models = ShadowModels(torch_wrapper, num_shadow_models=3)

# Rest of the code remains the same
shadow_dataset = shadow_models.generate_shadow_dataset(x_train_shadow, y_train_shadow)
(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset

# Shadow models' accuracy
print([sm.model.score(x_test_shadow, y_test_shadow) for sm in shadow_models.get_shadow_models()])
