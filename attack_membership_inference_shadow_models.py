import tensorflow as tf
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import StandardScaler
import load_data

# load data
tf.compat.v1.disable_eager_execution()

# import load_data.py and use load_malware_images() and load_benign_images() to load the data
malware_images = tf.convert_to_tensor(load_data.load_malware_images())
benign_images = tf.convert_to_tensor(load_data.load_benign_images())

# Reshape the tensors to have 2 dimensions
malware_images_2d = tf.reshape(malware_images, (malware_images.shape[0], -1))
benign_images_2d = tf.reshape(benign_images, (benign_images.shape[0], -1))

# Convert tensors to numpy arrays for scaling
malware_images_2d_np = malware_images_2d.numpy()
benign_images_2d_np = benign_images_2d.numpy()

# Apply the StandardScaler
scaler = StandardScaler()
malware_images_scaled = scaler.fit_transform(malware_images_2d_np)
benign_images_scaled = scaler.fit_transform(benign_images_2d_np)

# Convert back to tensors
malware_images_scaled_2d = tf.convert_to_tensor(malware_images_scaled)
benign_images_scaled_2d = tf.convert_to_tensor(benign_images_scaled)

# Reshape the scaled tensors back to the original 3D shape
malware_images_scaled_3d = tf.reshape(malware_images_scaled_2d, malware_images.shape)
benign_images_scaled_3d = tf.reshape(benign_images_scaled_2d, benign_images.shape)

# reshape the tensors to have 90x90x1 dimensions
malware_images_scaled_3d = tf.reshape(malware_images_scaled_3d, (malware_images_scaled_3d.shape[0], 28, 28, 1))
benign_images_scaled_3d = tf.reshape(benign_images_scaled_3d, (benign_images_scaled_3d.shape[0], 28, 28, 1))

x = np.concatenate((malware_images_scaled_3d, benign_images_scaled_3d), axis=0)
y = np.concatenate((np.ones(len(malware_images_scaled_3d)), np.zeros(len(benign_images_scaled_3d))))

# Shuffle data
shuffle_idx = np.random.permutation(len(x))
x = x[shuffle_idx]
y = y[shuffle_idx]

# split data to 80 percent training and 20 percent testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
# (x_target, y_target), (x_shadow, y_shadow), _, _ = train_test_split(x,y, test_set=0.2)

# for my shadow model, I will reverse them, using test as training and training as test
x_train_shadow, x_test_shadow, y_train_shadow, y_test_shadow = x_test, x_train, y_test, y_train
# x_shadow = np.concatenate((x_test, y_test), axis=0)
# y_shadow = np.concatenate((x_train, y_train), axis=0)

# my original model
# model = tf.keras.models.Sequential([
#     tf.keras.layers.Reshape((90, 90, 1), input_shape=(90, 90)),
#     tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),
#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
#     tf.keras.layers.Flatten(),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dense(1, activation='sigmoid')
# ])

model = tf.keras.models.Sequential([
    # tf.keras.layers.Reshape((90, 90, 1), input_shape=(90, 90)),

    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))
model.fit(x_train, y_train, epochs=1, batch_size=32, validation_data=(x_test, y_test))

# print the accuracy of the model
print("Accuracy of the Original model: ", model.evaluate(x_test, y_test)[1])

# print the differnt evaluation metrics
from sklearn.metrics import classification_report

y_pred = model.predict(x_test)
y_pred = np.round(y_pred)
print("Classification Report of the Original model: \n", classification_report(y_test, y_pred))

# disable eager execution

from art.attacks.inference.membership_inference import ShadowModels
from art.estimators.classification import KerasClassifier

# Create a KerasClassifier using the simple model
art_classifier = KerasClassifier(model=model, clip_values=(0, 1))

# Generate shadow dataset
shadow_models = ShadowModels(art_classifier, num_shadow_models=3)
shadow_dataset = shadow_models.generate_shadow_dataset(x_train_shadow, y_train_shadow)
(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset

shadow_models = ShadowModels(art_classifier, num_shadow_models=3)

shadow_dataset = shadow_models.generate_shadow_dataset(x_train_shadow, y_train_shadow)
(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset

# Shadow models' accuracy
print([sm.model.score(x_test_shadow, y_test_shadow) for sm in shadow_models.get_shadow_models()])
